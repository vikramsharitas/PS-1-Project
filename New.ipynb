{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "New.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikramsharitas/PS-1-Project/blob/master/New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9faYH5amrEJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4849f611-49ae-4f77-bd32-caa148f982a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7rZnJaGTWQw0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d9fdd217-0f81-4b27-8b6b-5c0bf9686877"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sofxGVm66fMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_excel('/content/drive/My Drive/Data/Data/FutureTech_Sampledata.xlsx', parse_dates=['datetime'])\n",
        "yval = df['RPM'] == 0\n",
        "df['yval'] = yval\n",
        "# df = df[df['machineID']==1]\n",
        "length = len(df)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ojHE-iCCWIhz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0f275899-83d9-4501-97d2-9771e04f3b60"
      },
      "source": [
        "df.head(90000)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>machineID</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>RPM</th>\n",
              "      <th>pressure</th>\n",
              "      <th>vibration</th>\n",
              "      <th>yval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-01 06:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>176.217853</td>\n",
              "      <td>418.504078</td>\n",
              "      <td>113.077935</td>\n",
              "      <td>45.087686</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-01 07:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>162.879223</td>\n",
              "      <td>402.747490</td>\n",
              "      <td>95.460525</td>\n",
              "      <td>43.413973</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-01 08:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>170.989902</td>\n",
              "      <td>527.349825</td>\n",
              "      <td>75.237905</td>\n",
              "      <td>34.178847</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-01-01 09:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>162.462833</td>\n",
              "      <td>346.149335</td>\n",
              "      <td>109.248561</td>\n",
              "      <td>41.122144</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-01-01 10:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>157.610021</td>\n",
              "      <td>435.376873</td>\n",
              "      <td>111.886648</td>\n",
              "      <td>25.990511</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43800</th>\n",
              "      <td>2016-01-01 02:00:00</td>\n",
              "      <td>5</td>\n",
              "      <td>162.964887</td>\n",
              "      <td>511.046527</td>\n",
              "      <td>153.187090</td>\n",
              "      <td>41.772148</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43801</th>\n",
              "      <td>2016-01-01 03:00:00</td>\n",
              "      <td>5</td>\n",
              "      <td>136.402165</td>\n",
              "      <td>402.228972</td>\n",
              "      <td>152.191926</td>\n",
              "      <td>38.078241</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43802</th>\n",
              "      <td>2016-01-01 04:00:00</td>\n",
              "      <td>5</td>\n",
              "      <td>181.426439</td>\n",
              "      <td>460.280665</td>\n",
              "      <td>142.451849</td>\n",
              "      <td>44.551477</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43803</th>\n",
              "      <td>2016-01-01 05:00:00</td>\n",
              "      <td>5</td>\n",
              "      <td>178.261658</td>\n",
              "      <td>424.821800</td>\n",
              "      <td>156.228631</td>\n",
              "      <td>39.976910</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43804</th>\n",
              "      <td>2016-01-01 06:00:00</td>\n",
              "      <td>5</td>\n",
              "      <td>178.789197</td>\n",
              "      <td>415.167298</td>\n",
              "      <td>142.414273</td>\n",
              "      <td>47.020210</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43805 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 datetime  machineID     Voltage  ...    pressure  vibration   yval\n",
              "0     2015-01-01 06:00:00          1  176.217853  ...  113.077935  45.087686  False\n",
              "1     2015-01-01 07:00:00          1  162.879223  ...   95.460525  43.413973  False\n",
              "2     2015-01-01 08:00:00          1  170.989902  ...   75.237905  34.178847  False\n",
              "3     2015-01-01 09:00:00          1  162.462833  ...  109.248561  41.122144  False\n",
              "4     2015-01-01 10:00:00          1  157.610021  ...  111.886648  25.990511  False\n",
              "...                   ...        ...         ...  ...         ...        ...    ...\n",
              "43800 2016-01-01 02:00:00          5  162.964887  ...  153.187090  41.772148  False\n",
              "43801 2016-01-01 03:00:00          5  136.402165  ...  152.191926  38.078241  False\n",
              "43802 2016-01-01 04:00:00          5  181.426439  ...  142.451849  44.551477  False\n",
              "43803 2016-01-01 05:00:00          5  178.261658  ...  156.228631  39.976910  False\n",
              "43804 2016-01-01 06:00:00          5  178.789197  ...  142.414273  47.020210  False\n",
              "\n",
              "[43805 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNr4Gx0ctBDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_hrs(length, yval):\n",
        "  hoursto = np.zeros(length)\n",
        "  hourssince = np.zeros(length)\n",
        "  l = len(yval)\n",
        "  temp1 = None\n",
        "  temp2 = None\n",
        "  for i in range(length-1, -1, -1):\n",
        "    if yval[i] == 1:\n",
        "      temp1 = 1\n",
        "      hoursto[(i)] = 0\n",
        "      continue\n",
        "    if temp1 == 1:\n",
        "      hoursto[(i)] = hoursto[(i)+1] + 1\n",
        "    else:\n",
        "      hoursto[(i)] = None\n",
        "    if yval[length-1-(i)] == 1:\n",
        "      temp2 = 1\n",
        "      hourssince[length-1-(i)] = 0\n",
        "      continue\n",
        "    if temp2 == 1:\n",
        "      hourssince[length-1-(i)] = hourssince[length-1-(i)-1] + 1\n",
        "    else:\n",
        "      hourssince[length-1-(i)] = None\n",
        "  return hoursto, hourssince"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTmF2J-cqTz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "since = np.zeros(0)\n",
        "to = np.zeros(0)\n",
        "\n",
        "for mid in df.machineID.unique():\n",
        "  l = len(df[df.machineID == mid])\n",
        "  yval = df.yval[df.machineID == mid].values\n",
        "\n",
        "  hrsince = np.zeros(l)\n",
        "  hrsto = np.zeros(l)\n",
        "\n",
        "  temp1 = -1\n",
        "  temp2 = -1\n",
        "  \n",
        "  for i in range(0, l):\n",
        "    if yval[i] == 1:\n",
        "      temp1 = 1\n",
        "      hrsince[i] == 0\n",
        "    elif temp1 == 1:\n",
        "      hrsince[i] = hrsince[i-1] + 1\n",
        "\n",
        "    if yval[l-i-1] == 1:\n",
        "      temp2 = 1\n",
        "      hrsto[l-i-1] = 0\n",
        "    elif temp2 == 1:\n",
        "      hrsto[l-i-1] = hrsto[l-i] + 1\n",
        "\n",
        "  temp1 = -1\n",
        "  temp2 = -1\n",
        "\n",
        "  for i in range(0, l):\n",
        "    if hrsto[i] == 0 and hrsto[i-1] == 0:\n",
        "      temp2 = 1\n",
        "      hrsto[i] = 720\n",
        "    elif temp2 == 1:\n",
        "      hrsto[i] = hrsto[i-1] - 1\n",
        "    \n",
        "    if hrsince[l-i-1] == 0 and hrsince[l-i] == 0:\n",
        "      temp1 = 1\n",
        "      hrsince[l-i-1] = 720\n",
        "    elif temp1 == 1:\n",
        "      hrsince[l-i-1] = hrsince[l-i] - 1\n",
        "\n",
        "  since = np.append(since, hrsince)\n",
        "  to = np.append(to, hrsto)\n",
        "\n",
        "df['hourssince'] = since\n",
        "df['hoursto'] = to"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFHr3Gc-u-Lw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3101b18c-2169-4706-f435-36f4c28af0a2"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 datetime  machineID     Voltage  ...   yval  hourssince  hoursto\n",
            "0     2015-01-01 06:00:00          1  176.217853  ...  False       642.0     79.0\n",
            "1     2015-01-01 07:00:00          1  162.879223  ...  False       643.0     78.0\n",
            "2     2015-01-01 08:00:00          1  170.989902  ...  False       644.0     77.0\n",
            "3     2015-01-01 09:00:00          1  162.462833  ...  False       645.0     76.0\n",
            "4     2015-01-01 10:00:00          1  157.610021  ...  False       646.0     75.0\n",
            "...                   ...        ...         ...  ...    ...         ...      ...\n",
            "43800 2016-01-01 02:00:00          5  162.964887  ...  False         2.0    719.0\n",
            "43801 2016-01-01 03:00:00          5  136.402165  ...  False         3.0    718.0\n",
            "43802 2016-01-01 04:00:00          5  181.426439  ...  False         4.0    717.0\n",
            "43803 2016-01-01 05:00:00          5  178.261658  ...  False         5.0    716.0\n",
            "43804 2016-01-01 06:00:00          5  178.789197  ...  False         6.0    715.0\n",
            "\n",
            "[43805 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IfQUSiJfUpXJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fb8dc0df-7d48-41b3-bf61-d05d8faf0dc8"
      },
      "source": [
        "features_considered = ['datetime','Voltage','RPM','pressure','vibration','hourssince','hoursto']\n",
        "features = df[features_considered]\n",
        "# features.index = df.index\n",
        "features.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>RPM</th>\n",
              "      <th>pressure</th>\n",
              "      <th>vibration</th>\n",
              "      <th>hourssince</th>\n",
              "      <th>hoursto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-01 06:00:00</td>\n",
              "      <td>176.217853</td>\n",
              "      <td>418.504078</td>\n",
              "      <td>113.077935</td>\n",
              "      <td>45.087686</td>\n",
              "      <td>642.0</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-01 07:00:00</td>\n",
              "      <td>162.879223</td>\n",
              "      <td>402.747490</td>\n",
              "      <td>95.460525</td>\n",
              "      <td>43.413973</td>\n",
              "      <td>643.0</td>\n",
              "      <td>78.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-01 08:00:00</td>\n",
              "      <td>170.989902</td>\n",
              "      <td>527.349825</td>\n",
              "      <td>75.237905</td>\n",
              "      <td>34.178847</td>\n",
              "      <td>644.0</td>\n",
              "      <td>77.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-01-01 09:00:00</td>\n",
              "      <td>162.462833</td>\n",
              "      <td>346.149335</td>\n",
              "      <td>109.248561</td>\n",
              "      <td>41.122144</td>\n",
              "      <td>645.0</td>\n",
              "      <td>76.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-01-01 10:00:00</td>\n",
              "      <td>157.610021</td>\n",
              "      <td>435.376873</td>\n",
              "      <td>111.886648</td>\n",
              "      <td>25.990511</td>\n",
              "      <td>646.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             datetime     Voltage         RPM  ...  vibration  hourssince  hoursto\n",
              "0 2015-01-01 06:00:00  176.217853  418.504078  ...  45.087686       642.0     79.0\n",
              "1 2015-01-01 07:00:00  162.879223  402.747490  ...  43.413973       643.0     78.0\n",
              "2 2015-01-01 08:00:00  170.989902  527.349825  ...  34.178847       644.0     77.0\n",
              "3 2015-01-01 09:00:00  162.462833  346.149335  ...  41.122144       645.0     76.0\n",
              "4 2015-01-01 10:00:00  157.610021  435.376873  ...  25.990511       646.0     75.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7VuNIwfHRHx",
        "colab": {}
      },
      "source": [
        "TRAIN_SPLIT = 40000\n",
        "dataset = features.values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d-rVX4d3OF86",
        "colab": {}
      },
      "source": [
        "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step, single_step=False):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i, step)\n",
        "    data.append(dataset[indices])\n",
        "\n",
        "    if single_step:\n",
        "      labels.append(target[i+target_size])\n",
        "    else:\n",
        "      labels.append(target[i:i+target_size])\n",
        "\n",
        "  return np.array(data), np.array(labels)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ZAdeAnP5c72",
        "colab": {}
      },
      "source": [
        "def plot_train_history(history, title):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(loss))\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z4GzBFBUNAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_time_steps(length):\n",
        "  return list(range(-length, 0))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqujLijCUAp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_plot(plot_data, delta, title):\n",
        "  labels = ['History', 'True Future', 'Model Prediction']\n",
        "  marker = ['.-', 'rx', 'go']\n",
        "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "  if delta:\n",
        "    future = delta\n",
        "  else:\n",
        "    future = 0\n",
        "\n",
        "  plt.title(title)\n",
        "  for i, x in enumerate(plot_data):\n",
        "    if i:\n",
        "      plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "               label=labels[i])\n",
        "    else:\n",
        "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "  plt.legend()\n",
        "  plt.xlim([time_steps[0], (future+5)*2])\n",
        "  plt.xlabel('Time-Step')\n",
        "  return plt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HlhVGzPhmMYI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40e4f049-c483-4c82-b3d6-f247585bcb9b"
      },
      "source": [
        "past_history = 744\n",
        "future_target = -1\n",
        "STEP = 1\n",
        "print(len(dataset))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kZCk9fqyJZqX",
        "colab": {}
      },
      "source": [
        "x_train_single, y_train_single = multivariate_data(dataset[:, 1:5], dataset[:, 6], 0,\n",
        "                                                 TRAIN_SPLIT-future_target+1, past_history,\n",
        "                                                 future_target, STEP, True)\n",
        "x_val_single, y_val_single = multivariate_data(dataset[:, 1:5], dataset[:, 6],\n",
        "                                             TRAIN_SPLIT, None, past_history,\n",
        "                                             future_target, STEP, True)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnSrOX_3ScPO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "52e56057-db7e-4439-8233-145d84fcd40a"
      },
      "source": [
        "print(x_train_single.shape)\n",
        "print(y_train_single.shape)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(39258, 744, 4)\n",
            "(39258,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cjR4PJArMOpA",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 64\n",
        "train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single.astype(np.float32), y_train_single.astype(np.float32)))\n",
        "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single.astype(np.float32), y_val_single.astype(np.float32)))\n",
        "val_data_single = val_data_single.batch(BATCH_SIZE)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kymA8sMDUuxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "single_step_model = tf.keras.models.Sequential()\n",
        "single_step_model.add(tf.keras.layers.Flatten())\n",
        "single_step_model.add(tf.keras.layers.Dense(600,activation='relu'))\n",
        "single_step_model.add(tf.keras.layers.Dense(400,activation='relu'))\n",
        "single_step_model.add(tf.keras.layers.Dense(200,activation='relu'))\n",
        "single_step_model.add(tf.keras.layers.Dense(100,activation='relu'))\n",
        "single_step_model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
        "single_step_model.add(tf.keras.layers.Dense(16,activation='relu'))\n",
        "single_step_model.add(tf.keras.layers.Dense(4,activation='relu'))\n",
        "single_step_model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "single_step_model.compile(optimizer='adam', loss=tf.keras.losses.MeanAbsoluteError(), metrics=['acc'])"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U0jnt2l2mwkl",
        "colab": {}
      },
      "source": [
        "EVALUATION_INTERVAL = 300\n",
        "EPOCHS = 200"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7uwOhXo3Oems",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42d100a1-e5b5-45ef-a0dd-7e02c1e681d1"
      },
      "source": [
        "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
        "                                          validation_data=val_data_single)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 419.4844 - acc: 0.0011 - val_loss: 299.8544 - val_acc: 0.0013\n",
            "Epoch 2/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 428.5116 - acc: 0.0011 - val_loss: 310.5401 - val_acc: 0.0013\n",
            "Epoch 3/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 448.9979 - acc: 0.0011 - val_loss: 413.5793 - val_acc: 0.0013\n",
            "Epoch 4/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 460.1651 - acc: 0.0011 - val_loss: 309.7716 - val_acc: 0.0013\n",
            "Epoch 5/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 461.5569 - acc: 0.0011 - val_loss: 377.2574 - val_acc: 0.0013\n",
            "Epoch 6/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 473.0490 - acc: 0.0011 - val_loss: 279.0229 - val_acc: 0.0013\n",
            "Epoch 7/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 470.5310 - acc: 0.0011 - val_loss: 344.1648 - val_acc: 0.0013\n",
            "Epoch 8/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 475.8515 - acc: 0.0011 - val_loss: 336.3379 - val_acc: 0.0013\n",
            "Epoch 9/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 481.5574 - acc: 0.0011 - val_loss: 395.0721 - val_acc: 0.0013\n",
            "Epoch 10/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 486.6345 - acc: 0.0011 - val_loss: 305.8064 - val_acc: 0.0013\n",
            "Epoch 11/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 482.7400 - acc: 0.0011 - val_loss: 259.6313 - val_acc: 0.0013\n",
            "Epoch 12/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 490.9664 - acc: 0.0011 - val_loss: 297.9427 - val_acc: 0.0013\n",
            "Epoch 13/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 489.7543 - acc: 0.0011 - val_loss: 320.8754 - val_acc: 0.0013\n",
            "Epoch 14/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 496.3514 - acc: 0.0011 - val_loss: 232.9937 - val_acc: 0.0013\n",
            "Epoch 15/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 486.8816 - acc: 0.0011 - val_loss: 323.5340 - val_acc: 0.0013\n",
            "Epoch 16/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 493.6319 - acc: 0.0011 - val_loss: 230.1281 - val_acc: 0.0013\n",
            "Epoch 17/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 476.9406 - acc: 0.0011 - val_loss: 351.5934 - val_acc: 0.0013\n",
            "Epoch 18/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 486.5233 - acc: 0.0011 - val_loss: 229.9170 - val_acc: 0.0013\n",
            "Epoch 19/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 495.4685 - acc: 0.0011 - val_loss: 224.9761 - val_acc: 0.0013\n",
            "Epoch 20/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 500.9862 - acc: 0.0011 - val_loss: 266.0396 - val_acc: 0.0013\n",
            "Epoch 21/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 491.2849 - acc: 0.0011 - val_loss: 231.7167 - val_acc: 0.0013\n",
            "Epoch 22/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 502.4013 - acc: 0.0011 - val_loss: 261.5623 - val_acc: 0.0013\n",
            "Epoch 23/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 505.5701 - acc: 0.0011 - val_loss: 365.8217 - val_acc: 0.0013\n",
            "Epoch 24/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 481.0756 - acc: 0.0011 - val_loss: 385.1756 - val_acc: 0.0013\n",
            "Epoch 25/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 499.7797 - acc: 0.0011 - val_loss: 229.9617 - val_acc: 0.0013\n",
            "Epoch 26/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 503.6003 - acc: 0.0011 - val_loss: 225.0965 - val_acc: 0.0013\n",
            "Epoch 27/200\n",
            "614/614 [==============================] - 3s 4ms/step - loss: 506.2082 - acc: 0.0011 - val_loss: 224.6504 - val_acc: 0.0013\n",
            "Epoch 28/200\n",
            "614/614 [==============================] - 3s 4ms/step - loss: 506.2526 - acc: 0.0011 - val_loss: 226.1830 - val_acc: 0.0013\n",
            "Epoch 29/200\n",
            "614/614 [==============================] - 3s 4ms/step - loss: 471.7155 - acc: 0.0011 - val_loss: 279.4203 - val_acc: 0.0013\n",
            "Epoch 30/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 488.4248 - acc: 0.0011 - val_loss: 226.8246 - val_acc: 0.0013\n",
            "Epoch 31/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 503.6739 - acc: 0.0011 - val_loss: 224.2219 - val_acc: 0.0013\n",
            "Epoch 32/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 509.8592 - acc: 0.0011 - val_loss: 226.5756 - val_acc: 0.0013\n",
            "Epoch 33/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 512.9972 - acc: 0.0011 - val_loss: 220.5010 - val_acc: 0.0013\n",
            "Epoch 34/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 508.8048 - acc: 0.0011 - val_loss: 218.9860 - val_acc: 0.0013\n",
            "Epoch 35/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 512.8043 - acc: 0.0011 - val_loss: 222.3063 - val_acc: 0.0013\n",
            "Epoch 36/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 511.4344 - acc: 0.0011 - val_loss: 266.2205 - val_acc: 0.0013\n",
            "Epoch 37/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 508.0524 - acc: 0.0011 - val_loss: 229.3445 - val_acc: 0.0013\n",
            "Epoch 38/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 512.3102 - acc: 0.0011 - val_loss: 224.0565 - val_acc: 0.0013\n",
            "Epoch 39/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 513.6695 - acc: 0.0011 - val_loss: 259.5419 - val_acc: 0.0013\n",
            "Epoch 40/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 512.2449 - acc: 0.0011 - val_loss: 230.9187 - val_acc: 0.0013\n",
            "Epoch 41/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 514.7737 - acc: 0.0011 - val_loss: 222.5704 - val_acc: 0.0013\n",
            "Epoch 42/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 515.9124 - acc: 0.0011 - val_loss: 247.4781 - val_acc: 0.0013\n",
            "Epoch 43/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 512.4538 - acc: 0.0011 - val_loss: 253.2818 - val_acc: 0.0013\n",
            "Epoch 44/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 516.6985 - acc: 0.0011 - val_loss: 223.5355 - val_acc: 0.0013\n",
            "Epoch 45/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 516.9221 - acc: 0.0011 - val_loss: 224.8596 - val_acc: 0.0013\n",
            "Epoch 46/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 517.6856 - acc: 0.0011 - val_loss: 223.8635 - val_acc: 0.0013\n",
            "Epoch 47/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 518.3668 - acc: 0.0011 - val_loss: 219.8119 - val_acc: 0.0013\n",
            "Epoch 48/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 517.9001 - acc: 0.0011 - val_loss: 224.6377 - val_acc: 0.0013\n",
            "Epoch 49/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 518.5987 - acc: 0.0011 - val_loss: 223.2265 - val_acc: 0.0013\n",
            "Epoch 50/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 518.2722 - acc: 0.0011 - val_loss: 219.0903 - val_acc: 0.0013\n",
            "Epoch 51/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 520.1784 - acc: 0.0011 - val_loss: 227.0939 - val_acc: 0.0013\n",
            "Epoch 52/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 518.2247 - acc: 0.0011 - val_loss: 223.8517 - val_acc: 0.0013\n",
            "Epoch 53/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 520.3132 - acc: 0.0011 - val_loss: 219.5861 - val_acc: 0.0013\n",
            "Epoch 54/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 520.8192 - acc: 0.0011 - val_loss: 236.4925 - val_acc: 0.0013\n",
            "Epoch 55/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 520.6220 - acc: 0.0011 - val_loss: 266.6682 - val_acc: 0.0013\n",
            "Epoch 56/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 522.6927 - acc: 0.0011 - val_loss: 218.3083 - val_acc: 0.0013\n",
            "Epoch 57/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 520.5210 - acc: 0.0011 - val_loss: 252.1570 - val_acc: 0.0013\n",
            "Epoch 58/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 515.4219 - acc: 0.0011 - val_loss: 219.6991 - val_acc: 0.0013\n",
            "Epoch 59/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 519.3522 - acc: 0.0011 - val_loss: 217.9706 - val_acc: 0.0013\n",
            "Epoch 60/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 521.4896 - acc: 0.0011 - val_loss: 220.8613 - val_acc: 0.0013\n",
            "Epoch 61/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 501.3677 - acc: 0.0011 - val_loss: 222.2752 - val_acc: 0.0013\n",
            "Epoch 62/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 518.3734 - acc: 0.0011 - val_loss: 220.8200 - val_acc: 0.0013\n",
            "Epoch 63/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 518.5643 - acc: 0.0011 - val_loss: 218.3731 - val_acc: 0.0013\n",
            "Epoch 64/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 520.1953 - acc: 0.0011 - val_loss: 218.3187 - val_acc: 0.0013\n",
            "Epoch 65/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 514.8716 - acc: 0.0011 - val_loss: 240.3431 - val_acc: 0.0013\n",
            "Epoch 66/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 460.8646 - acc: 0.0011 - val_loss: 235.7256 - val_acc: 0.0013\n",
            "Epoch 67/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 495.8773 - acc: 0.0011 - val_loss: 223.8665 - val_acc: 0.0013\n",
            "Epoch 68/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 482.3075 - acc: 0.0011 - val_loss: 349.4357 - val_acc: 0.0013\n",
            "Epoch 69/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 469.0627 - acc: 0.0011 - val_loss: 306.8636 - val_acc: 0.0013\n",
            "Epoch 70/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 479.6101 - acc: 0.0011 - val_loss: 341.4881 - val_acc: 0.0013\n",
            "Epoch 71/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 494.0838 - acc: 0.0011 - val_loss: 233.2608 - val_acc: 0.0013\n",
            "Epoch 72/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 502.8781 - acc: 0.0011 - val_loss: 230.2161 - val_acc: 0.0013\n",
            "Epoch 73/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 493.8441 - acc: 0.0011 - val_loss: 265.2915 - val_acc: 0.0013\n",
            "Epoch 74/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 490.9599 - acc: 0.0011 - val_loss: 227.1004 - val_acc: 0.0013\n",
            "Epoch 75/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 506.3030 - acc: 0.0011 - val_loss: 228.1569 - val_acc: 0.0013\n",
            "Epoch 76/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 510.2759 - acc: 0.0011 - val_loss: 221.7586 - val_acc: 0.0013\n",
            "Epoch 77/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 509.2770 - acc: 0.0011 - val_loss: 225.6319 - val_acc: 0.0013\n",
            "Epoch 78/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 512.0964 - acc: 0.0011 - val_loss: 226.0029 - val_acc: 0.0013\n",
            "Epoch 79/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 513.1809 - acc: 0.0011 - val_loss: 220.5533 - val_acc: 0.0013\n",
            "Epoch 80/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 512.5641 - acc: 0.0011 - val_loss: 232.3034 - val_acc: 0.0013\n",
            "Epoch 81/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 512.7512 - acc: 0.0011 - val_loss: 234.8692 - val_acc: 0.0013\n",
            "Epoch 82/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 511.8500 - acc: 0.0011 - val_loss: 237.5891 - val_acc: 0.0013\n",
            "Epoch 83/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 511.5800 - acc: 0.0011 - val_loss: 223.7141 - val_acc: 0.0013\n",
            "Epoch 84/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 514.4506 - acc: 0.0011 - val_loss: 223.4167 - val_acc: 0.0013\n",
            "Epoch 85/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 513.2284 - acc: 0.0011 - val_loss: 223.4358 - val_acc: 0.0013\n",
            "Epoch 86/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 517.5213 - acc: 0.0011 - val_loss: 226.1072 - val_acc: 0.0013\n",
            "Epoch 87/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 515.9429 - acc: 0.0011 - val_loss: 221.7879 - val_acc: 0.0013\n",
            "Epoch 88/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 518.2799 - acc: 0.0011 - val_loss: 219.6966 - val_acc: 0.0013\n",
            "Epoch 89/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 498.9743 - acc: 0.0011 - val_loss: 346.6742 - val_acc: 0.0013\n",
            "Epoch 90/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 512.3813 - acc: 0.0011 - val_loss: 263.7546 - val_acc: 0.0013\n",
            "Epoch 91/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 515.8218 - acc: 0.0011 - val_loss: 219.1376 - val_acc: 0.0013\n",
            "Epoch 92/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 516.1523 - acc: 0.0011 - val_loss: 222.0196 - val_acc: 0.0013\n",
            "Epoch 93/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 517.4673 - acc: 0.0011 - val_loss: 219.2835 - val_acc: 0.0013\n",
            "Epoch 94/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 501.6358 - acc: 0.0011 - val_loss: 299.2620 - val_acc: 0.0013\n",
            "Epoch 95/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 500.9461 - acc: 0.0011 - val_loss: 291.7013 - val_acc: 0.0013\n",
            "Epoch 96/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 493.3300 - acc: 0.0011 - val_loss: 248.8414 - val_acc: 0.0013\n",
            "Epoch 97/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 513.9741 - acc: 0.0011 - val_loss: 221.8600 - val_acc: 0.0013\n",
            "Epoch 98/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 517.9684 - acc: 0.0011 - val_loss: 218.9701 - val_acc: 0.0013\n",
            "Epoch 99/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 520.3518 - acc: 0.0011 - val_loss: 221.4423 - val_acc: 0.0013\n",
            "Epoch 100/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 520.0235 - acc: 0.0011 - val_loss: 220.7892 - val_acc: 0.0013\n",
            "Epoch 101/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 522.1063 - acc: 0.0011 - val_loss: 219.6773 - val_acc: 0.0013\n",
            "Epoch 102/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 523.6790 - acc: 0.0011 - val_loss: 222.5559 - val_acc: 0.0013\n",
            "Epoch 103/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 519.7843 - acc: 0.0011 - val_loss: 218.6517 - val_acc: 0.0013\n",
            "Epoch 104/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 521.9703 - acc: 0.0011 - val_loss: 218.2042 - val_acc: 0.0013\n",
            "Epoch 105/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 523.4076 - acc: 0.0011 - val_loss: 220.3956 - val_acc: 0.0013\n",
            "Epoch 106/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 526.1326 - acc: 0.0011 - val_loss: 222.9395 - val_acc: 0.0013\n",
            "Epoch 107/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 525.9156 - acc: 0.0011 - val_loss: 216.9316 - val_acc: 0.0013\n",
            "Epoch 108/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 524.3560 - acc: 0.0011 - val_loss: 225.5172 - val_acc: 0.0013\n",
            "Epoch 109/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 526.0743 - acc: 0.0011 - val_loss: 222.4837 - val_acc: 0.0013\n",
            "Epoch 110/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 519.9494 - acc: 0.0011 - val_loss: 222.0403 - val_acc: 0.0013\n",
            "Epoch 111/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 522.6892 - acc: 0.0011 - val_loss: 217.2203 - val_acc: 0.0013\n",
            "Epoch 112/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 524.9801 - acc: 0.0011 - val_loss: 219.1710 - val_acc: 0.0013\n",
            "Epoch 113/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 525.5617 - acc: 0.0011 - val_loss: 219.9769 - val_acc: 0.0013\n",
            "Epoch 114/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 526.5602 - acc: 0.0011 - val_loss: 218.2882 - val_acc: 0.0013\n",
            "Epoch 115/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 527.4454 - acc: 0.0011 - val_loss: 217.5093 - val_acc: 0.0013\n",
            "Epoch 116/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 528.7651 - acc: 0.0011 - val_loss: 218.6684 - val_acc: 0.0013\n",
            "Epoch 117/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 530.0905 - acc: 0.0011 - val_loss: 219.7174 - val_acc: 0.0013\n",
            "Epoch 118/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 530.0876 - acc: 0.0011 - val_loss: 218.9169 - val_acc: 0.0013\n",
            "Epoch 119/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 526.1010 - acc: 0.0011 - val_loss: 220.0622 - val_acc: 0.0013\n",
            "Epoch 120/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 529.3197 - acc: 0.0011 - val_loss: 218.6503 - val_acc: 0.0013\n",
            "Epoch 121/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 530.7497 - acc: 0.0011 - val_loss: 223.4875 - val_acc: 0.0013\n",
            "Epoch 122/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 532.3815 - acc: 0.0011 - val_loss: 219.2260 - val_acc: 0.0013\n",
            "Epoch 123/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 530.5539 - acc: 0.0011 - val_loss: 218.4502 - val_acc: 0.0013\n",
            "Epoch 124/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 532.5812 - acc: 0.0011 - val_loss: 237.7850 - val_acc: 0.0013\n",
            "Epoch 125/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 527.1812 - acc: 0.0011 - val_loss: 217.1727 - val_acc: 0.0013\n",
            "Epoch 126/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 531.2262 - acc: 0.0011 - val_loss: 219.7475 - val_acc: 0.0013\n",
            "Epoch 127/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 536.0547 - acc: 0.0011 - val_loss: 216.9716 - val_acc: 0.0013\n",
            "Epoch 128/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 534.2431 - acc: 0.0011 - val_loss: 266.1830 - val_acc: 0.0013\n",
            "Epoch 129/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 533.3496 - acc: 0.0011 - val_loss: 222.2104 - val_acc: 0.0013\n",
            "Epoch 130/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 530.5696 - acc: 0.0011 - val_loss: 217.5408 - val_acc: 0.0013\n",
            "Epoch 131/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 535.3807 - acc: 0.0011 - val_loss: 216.1821 - val_acc: 0.0013\n",
            "Epoch 132/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 536.3466 - acc: 0.0011 - val_loss: 218.1359 - val_acc: 0.0013\n",
            "Epoch 133/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 536.1202 - acc: 0.0011 - val_loss: 219.9719 - val_acc: 0.0013\n",
            "Epoch 134/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 537.4521 - acc: 0.0011 - val_loss: 218.0587 - val_acc: 0.0013\n",
            "Epoch 135/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 538.5779 - acc: 0.0011 - val_loss: 217.6857 - val_acc: 0.0013\n",
            "Epoch 136/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 538.6865 - acc: 0.0011 - val_loss: 217.7485 - val_acc: 0.0013\n",
            "Epoch 137/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 538.9316 - acc: 0.0011 - val_loss: 218.1743 - val_acc: 0.0013\n",
            "Epoch 138/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 539.6686 - acc: 0.0011 - val_loss: 218.3203 - val_acc: 0.0013\n",
            "Epoch 139/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 540.2294 - acc: 0.0011 - val_loss: 217.5022 - val_acc: 0.0013\n",
            "Epoch 140/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 540.0801 - acc: 0.0011 - val_loss: 218.8993 - val_acc: 0.0013\n",
            "Epoch 141/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 539.1343 - acc: 0.0011 - val_loss: 219.1309 - val_acc: 0.0013\n",
            "Epoch 142/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 539.5721 - acc: 0.0011 - val_loss: 216.9819 - val_acc: 0.0013\n",
            "Epoch 143/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 540.3134 - acc: 0.0011 - val_loss: 216.9481 - val_acc: 0.0013\n",
            "Epoch 144/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 540.9746 - acc: 0.0011 - val_loss: 215.3629 - val_acc: 0.0013\n",
            "Epoch 145/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 539.9194 - acc: 0.0011 - val_loss: 217.2619 - val_acc: 0.0013\n",
            "Epoch 146/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 542.1243 - acc: 0.0011 - val_loss: 218.4066 - val_acc: 0.0013\n",
            "Epoch 147/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 542.1559 - acc: 0.0011 - val_loss: 215.7990 - val_acc: 0.0013\n",
            "Epoch 148/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 540.8691 - acc: 0.0011 - val_loss: 218.1822 - val_acc: 0.0013\n",
            "Epoch 149/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 539.6510 - acc: 0.0011 - val_loss: 217.8459 - val_acc: 0.0013\n",
            "Epoch 150/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 539.6924 - acc: 0.0011 - val_loss: 215.5187 - val_acc: 0.0013\n",
            "Epoch 151/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 541.5745 - acc: 0.0011 - val_loss: 220.2955 - val_acc: 0.0013\n",
            "Epoch 152/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 541.0574 - acc: 0.0011 - val_loss: 216.6713 - val_acc: 0.0013\n",
            "Epoch 153/200\n",
            "614/614 [==============================] - 3s 4ms/step - loss: 530.4897 - acc: 0.0011 - val_loss: 217.4169 - val_acc: 0.0013\n",
            "Epoch 154/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 539.5056 - acc: 0.0011 - val_loss: 236.9597 - val_acc: 0.0013\n",
            "Epoch 155/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 522.0563 - acc: 0.0011 - val_loss: 215.0692 - val_acc: 0.0013\n",
            "Epoch 156/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 535.5468 - acc: 0.0011 - val_loss: 217.6816 - val_acc: 0.0013\n",
            "Epoch 157/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 535.4905 - acc: 0.0011 - val_loss: 220.8351 - val_acc: 0.0013\n",
            "Epoch 158/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 533.7564 - acc: 0.0011 - val_loss: 218.4180 - val_acc: 0.0013\n",
            "Epoch 159/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 537.1678 - acc: 0.0011 - val_loss: 218.5586 - val_acc: 0.0013\n",
            "Epoch 160/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 535.1467 - acc: 0.0011 - val_loss: 216.3260 - val_acc: 0.0013\n",
            "Epoch 161/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 536.9100 - acc: 0.0011 - val_loss: 218.4727 - val_acc: 0.0013\n",
            "Epoch 162/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 518.9448 - acc: 0.0011 - val_loss: 290.4409 - val_acc: 0.0013\n",
            "Epoch 163/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 528.9784 - acc: 0.0011 - val_loss: 219.7622 - val_acc: 0.0013\n",
            "Epoch 164/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 531.0546 - acc: 0.0011 - val_loss: 217.9852 - val_acc: 0.0013\n",
            "Epoch 165/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 535.4850 - acc: 0.0011 - val_loss: 218.9063 - val_acc: 0.0013\n",
            "Epoch 166/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 531.3196 - acc: 0.0011 - val_loss: 217.5206 - val_acc: 0.0013\n",
            "Epoch 167/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 532.8377 - acc: 0.0011 - val_loss: 217.3126 - val_acc: 0.0013\n",
            "Epoch 168/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 533.7284 - acc: 0.0011 - val_loss: 217.5396 - val_acc: 0.0013\n",
            "Epoch 169/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 536.1619 - acc: 0.0011 - val_loss: 220.5587 - val_acc: 0.0013\n",
            "Epoch 170/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 534.4689 - acc: 0.0011 - val_loss: 217.6088 - val_acc: 0.0013\n",
            "Epoch 171/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 537.7947 - acc: 0.0011 - val_loss: 219.0998 - val_acc: 0.0013\n",
            "Epoch 172/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 536.5218 - acc: 0.0011 - val_loss: 218.0574 - val_acc: 0.0013\n",
            "Epoch 173/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 536.1235 - acc: 0.0011 - val_loss: 218.8342 - val_acc: 0.0013\n",
            "Epoch 174/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 537.1407 - acc: 0.0011 - val_loss: 217.9217 - val_acc: 0.0013\n",
            "Epoch 175/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 538.0974 - acc: 0.0011 - val_loss: 217.7536 - val_acc: 0.0013\n",
            "Epoch 176/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 536.1201 - acc: 0.0011 - val_loss: 216.9382 - val_acc: 0.0013\n",
            "Epoch 177/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 538.5530 - acc: 0.0011 - val_loss: 216.7536 - val_acc: 0.0013\n",
            "Epoch 178/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 538.9954 - acc: 0.0011 - val_loss: 214.2603 - val_acc: 0.0013\n",
            "Epoch 179/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 537.1470 - acc: 0.0011 - val_loss: 218.5798 - val_acc: 0.0013\n",
            "Epoch 180/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 538.4338 - acc: 0.0011 - val_loss: 218.8051 - val_acc: 0.0013\n",
            "Epoch 181/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 539.9382 - acc: 0.0011 - val_loss: 219.3959 - val_acc: 0.0013\n",
            "Epoch 182/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 528.9857 - acc: 0.0011 - val_loss: 214.5524 - val_acc: 0.0013\n",
            "Epoch 183/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 537.6494 - acc: 0.0011 - val_loss: 217.4819 - val_acc: 0.0013\n",
            "Epoch 184/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 538.7184 - acc: 0.0011 - val_loss: 218.1373 - val_acc: 0.0013\n",
            "Epoch 185/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 539.2738 - acc: 0.0011 - val_loss: 215.2235 - val_acc: 0.0013\n",
            "Epoch 186/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 540.7853 - acc: 0.0011 - val_loss: 218.2595 - val_acc: 0.0013\n",
            "Epoch 187/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 537.9247 - acc: 0.0011 - val_loss: 216.6301 - val_acc: 0.0013\n",
            "Epoch 188/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 538.5974 - acc: 0.0011 - val_loss: 217.7950 - val_acc: 0.0013\n",
            "Epoch 189/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 542.3263 - acc: 0.0011 - val_loss: 217.5550 - val_acc: 0.0013\n",
            "Epoch 190/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 540.8492 - acc: 0.0011 - val_loss: 217.5105 - val_acc: 0.0013\n",
            "Epoch 191/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 541.6912 - acc: 0.0011 - val_loss: 217.8725 - val_acc: 0.0013\n",
            "Epoch 192/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 543.1464 - acc: 0.0011 - val_loss: 218.1976 - val_acc: 0.0013\n",
            "Epoch 193/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 540.1162 - acc: 0.0011 - val_loss: 215.2923 - val_acc: 0.0013\n",
            "Epoch 194/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 542.1607 - acc: 0.0011 - val_loss: 217.5589 - val_acc: 0.0013\n",
            "Epoch 195/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 541.2875 - acc: 0.0011 - val_loss: 219.2584 - val_acc: 0.0013\n",
            "Epoch 196/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 543.5293 - acc: 0.0011 - val_loss: 216.7947 - val_acc: 0.0013\n",
            "Epoch 197/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 540.0975 - acc: 0.0011 - val_loss: 217.6869 - val_acc: 0.0013\n",
            "Epoch 198/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 543.4216 - acc: 0.0011 - val_loss: 218.3387 - val_acc: 0.0013\n",
            "Epoch 199/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 542.6234 - acc: 0.0011 - val_loss: 218.8018 - val_acc: 0.0013\n",
            "Epoch 200/200\n",
            "614/614 [==============================] - 2s 4ms/step - loss: 543.7933 - acc: 0.0011 - val_loss: 215.3950 - val_acc: 0.0013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UKfQoBjQ5l7U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "5a05fe63-badc-4ed5-8ad5-b26fdcf4909d"
      },
      "source": [
        "plot_train_history(single_step_history, 'single-Step Training and validation loss')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dt22wq6fyIBU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dee6d5c8-ced4-49e0-bbbc-64186ea50f68"
      },
      "source": [
        "y1 = None\n",
        "for x, y in val_data_single.take(10):\n",
        "  if y1 != None:\n",
        "    y0 = single_step_model.predict(x)\n",
        "    print(y0)\n",
        "    print(y)\n",
        "#     z = [y1.numpy(), y[BUFFER_SIZE-1].numpy(), y0]\n",
        "#     show_plot(z, 0, 'Prediction')\n",
        "  y1 = y"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[464.75165]\n",
            " [465.04846]\n",
            " [465.12506]\n",
            " [465.00415]\n",
            " [465.00497]\n",
            " [465.044  ]\n",
            " [465.04138]\n",
            " [464.98648]\n",
            " [465.36792]\n",
            " [465.24594]\n",
            " [465.26224]\n",
            " [465.2671 ]\n",
            " [465.34106]\n",
            " [465.14102]\n",
            " [464.87207]\n",
            " [464.90625]\n",
            " [464.8905 ]\n",
            " [464.80847]\n",
            " [464.7515 ]\n",
            " [465.34518]\n",
            " [464.92365]\n",
            " [464.83365]\n",
            " [465.26843]\n",
            " [465.44833]\n",
            " [465.4492 ]\n",
            " [465.27753]\n",
            " [465.1715 ]\n",
            " [465.3876 ]\n",
            " [465.00604]\n",
            " [464.96616]\n",
            " [465.418  ]\n",
            " [464.92493]\n",
            " [464.76157]\n",
            " [464.84164]\n",
            " [464.85043]\n",
            " [464.8512 ]\n",
            " [465.029  ]\n",
            " [465.06665]\n",
            " [464.6147 ]\n",
            " [464.71463]\n",
            " [464.4252 ]\n",
            " [464.5333 ]\n",
            " [464.35376]\n",
            " [464.5135 ]\n",
            " [464.14917]\n",
            " [464.49454]\n",
            " [464.51828]\n",
            " [464.836  ]\n",
            " [464.7957 ]\n",
            " [464.48083]\n",
            " [464.75842]\n",
            " [464.8205 ]\n",
            " [464.62302]\n",
            " [464.711  ]\n",
            " [464.73154]\n",
            " [464.82162]\n",
            " [464.80157]\n",
            " [464.43808]\n",
            " [464.79742]\n",
            " [464.4617 ]\n",
            " [464.50378]\n",
            " [464.33554]\n",
            " [464.57663]\n",
            " [464.79382]]\n",
            "tf.Tensor(\n",
            "[452. 451. 450. 449. 448. 447. 446. 445. 444. 443. 442. 441. 440. 439.\n",
            " 438. 437. 436. 435. 434. 433. 432. 431. 430. 429. 428. 427. 426. 425.\n",
            " 424. 423. 422. 421. 420. 419. 418. 417. 416. 415. 414. 413. 412. 411.\n",
            " 410. 409. 408. 407. 406. 405. 404. 403. 402. 401. 400. 399. 398. 397.\n",
            " 396. 395. 394. 393. 392. 391. 390. 389.], shape=(64,), dtype=float32)\n",
            "[[464.87595]\n",
            " [464.83392]\n",
            " [465.0162 ]\n",
            " [464.88736]\n",
            " [464.8956 ]\n",
            " [464.93875]\n",
            " [464.8767 ]\n",
            " [464.81036]\n",
            " [465.11005]\n",
            " [465.05164]\n",
            " [464.9738 ]\n",
            " [464.7916 ]\n",
            " [465.08032]\n",
            " [464.98325]\n",
            " [465.34204]\n",
            " [465.1752 ]\n",
            " [464.86237]\n",
            " [465.2628 ]\n",
            " [465.27213]\n",
            " [465.37646]\n",
            " [465.5351 ]\n",
            " [464.96692]\n",
            " [465.2561 ]\n",
            " [465.2747 ]\n",
            " [465.42334]\n",
            " [465.21964]\n",
            " [465.67953]\n",
            " [465.2792 ]\n",
            " [465.4111 ]\n",
            " [465.5176 ]\n",
            " [465.14566]\n",
            " [464.6551 ]\n",
            " [464.99884]\n",
            " [465.16992]\n",
            " [464.83032]\n",
            " [465.10452]\n",
            " [464.97363]\n",
            " [464.95938]\n",
            " [464.68906]\n",
            " [464.82062]\n",
            " [464.98706]\n",
            " [464.85046]\n",
            " [464.89804]\n",
            " [464.76572]\n",
            " [464.88608]\n",
            " [464.88364]\n",
            " [464.80798]\n",
            " [464.85214]\n",
            " [465.15317]\n",
            " [465.0516 ]\n",
            " [465.12164]\n",
            " [465.04062]\n",
            " [465.0868 ]\n",
            " [465.34503]\n",
            " [465.1589 ]\n",
            " [464.9904 ]\n",
            " [465.08994]\n",
            " [465.23315]\n",
            " [465.34692]\n",
            " [465.41754]\n",
            " [465.68036]\n",
            " [465.46677]\n",
            " [465.76175]\n",
            " [465.63474]]\n",
            "tf.Tensor(\n",
            "[388. 387. 386. 385. 384. 383. 382. 381. 380. 379. 378. 377. 376. 375.\n",
            " 374. 373. 372. 371. 370. 369. 368. 367. 366. 365. 364. 363. 362. 361.\n",
            " 360. 359. 358. 357. 356. 355. 354. 353. 352. 351. 350. 349. 348. 347.\n",
            " 346. 345. 344. 343. 342. 341. 340. 339. 338. 337. 336. 335. 334. 333.\n",
            " 332. 331. 330. 329. 328. 327. 326. 325.], shape=(64,), dtype=float32)\n",
            "[[465.50287]\n",
            " [465.58258]\n",
            " [465.3798 ]\n",
            " [465.06763]\n",
            " [465.28696]\n",
            " [464.78036]\n",
            " [464.63672]\n",
            " [464.81918]\n",
            " [464.98102]\n",
            " [464.84998]\n",
            " [464.7322 ]\n",
            " [465.40454]\n",
            " [465.1167 ]\n",
            " [465.01175]\n",
            " [464.89722]\n",
            " [465.10953]\n",
            " [464.79843]\n",
            " [465.39267]\n",
            " [465.48428]\n",
            " [465.48883]\n",
            " [465.2504 ]\n",
            " [465.25458]\n",
            " [465.8367 ]\n",
            " [465.4159 ]\n",
            " [465.8414 ]\n",
            " [465.91043]\n",
            " [465.41528]\n",
            " [465.47284]\n",
            " [465.57962]\n",
            " [465.9961 ]\n",
            " [465.90128]\n",
            " [465.98804]\n",
            " [466.31158]\n",
            " [466.02246]\n",
            " [465.73596]\n",
            " [465.7989 ]\n",
            " [466.33157]\n",
            " [466.41394]\n",
            " [465.8993 ]\n",
            " [466.14413]\n",
            " [466.26804]\n",
            " [466.5476 ]\n",
            " [466.6758 ]\n",
            " [466.69348]\n",
            " [466.25662]\n",
            " [466.032  ]\n",
            " [465.78748]\n",
            " [465.889  ]\n",
            " [465.82553]\n",
            " [465.87137]\n",
            " [465.56567]\n",
            " [465.5561 ]\n",
            " [465.2221 ]\n",
            " [465.30774]\n",
            " [465.53036]\n",
            " [464.91522]\n",
            " [464.7705 ]\n",
            " [464.92688]\n",
            " [465.133  ]\n",
            " [464.61203]\n",
            " [464.86664]\n",
            " [464.78625]\n",
            " [464.68002]\n",
            " [464.79675]]\n",
            "tf.Tensor(\n",
            "[324. 323. 322. 321. 320. 319. 318. 317. 316. 315. 314. 313. 312. 311.\n",
            " 310. 309. 308. 307. 306. 305. 304. 303. 302. 301. 300. 299. 298. 297.\n",
            " 296. 295. 294. 293. 292. 291. 290. 289. 288. 287. 286. 285. 284. 283.\n",
            " 282. 281. 280. 279. 278. 277. 276. 275. 274. 273. 272. 271. 270. 269.\n",
            " 268. 267. 266. 265. 264. 263. 262. 261.], shape=(64,), dtype=float32)\n",
            "[[464.55692]\n",
            " [464.8046 ]\n",
            " [464.2583 ]\n",
            " [463.9784 ]\n",
            " [464.2273 ]\n",
            " [464.26715]\n",
            " [463.889  ]\n",
            " [464.20923]\n",
            " [463.82574]\n",
            " [463.79956]\n",
            " [463.90387]\n",
            " [464.07925]\n",
            " [463.47186]\n",
            " [463.49246]\n",
            " [463.55762]\n",
            " [463.56116]\n",
            " [463.27756]\n",
            " [463.2444 ]\n",
            " [463.2249 ]\n",
            " [463.14932]\n",
            " [463.04016]\n",
            " [463.32556]\n",
            " [463.192  ]\n",
            " [462.68732]\n",
            " [462.63818]\n",
            " [462.56082]\n",
            " [462.99033]\n",
            " [462.93488]\n",
            " [463.2066 ]\n",
            " [463.35083]\n",
            " [463.18954]\n",
            " [463.0399 ]\n",
            " [463.67474]\n",
            " [463.63388]\n",
            " [463.6816 ]\n",
            " [463.7968 ]\n",
            " [463.8883 ]\n",
            " [463.2473 ]\n",
            " [463.70435]\n",
            " [463.65732]\n",
            " [463.86752]\n",
            " [464.1519 ]\n",
            " [463.82297]\n",
            " [463.9518 ]\n",
            " [463.90424]\n",
            " [464.3067 ]\n",
            " [464.32703]\n",
            " [464.40677]\n",
            " [463.95862]\n",
            " [464.18243]\n",
            " [464.57767]\n",
            " [464.21756]\n",
            " [463.5537 ]\n",
            " [463.68906]\n",
            " [463.58725]\n",
            " [463.32565]\n",
            " [463.61246]\n",
            " [463.51096]\n",
            " [463.42996]\n",
            " [463.5371 ]\n",
            " [463.6039 ]\n",
            " [463.9808 ]\n",
            " [463.55966]\n",
            " [463.71085]]\n",
            "tf.Tensor(\n",
            "[260. 259. 258. 257. 256. 255. 254. 253. 252. 251. 250. 249. 248. 247.\n",
            " 246. 245. 244. 243. 242. 241. 240. 239. 238. 237. 236. 235. 234. 233.\n",
            " 232. 231. 230. 229. 228. 227. 226. 225. 224. 223. 222. 221. 220. 219.\n",
            " 218. 217. 216. 215. 214. 213. 212. 211. 210. 209. 208. 207. 206. 205.\n",
            " 204. 203. 202. 201. 200. 199. 198. 197.], shape=(64,), dtype=float32)\n",
            "[[463.8235 ]\n",
            " [463.47617]\n",
            " [463.5269 ]\n",
            " [463.60406]\n",
            " [463.5556 ]\n",
            " [463.30756]\n",
            " [463.39008]\n",
            " [463.18985]\n",
            " [463.57245]\n",
            " [463.20694]\n",
            " [463.57956]\n",
            " [463.57037]\n",
            " [463.00482]\n",
            " [463.55862]\n",
            " [463.8285 ]\n",
            " [463.3495 ]\n",
            " [463.40222]\n",
            " [463.6577 ]\n",
            " [463.4779 ]\n",
            " [463.25732]\n",
            " [463.56635]\n",
            " [463.36703]\n",
            " [463.26578]\n",
            " [463.41367]\n",
            " [463.17023]\n",
            " [463.24023]\n",
            " [463.06232]\n",
            " [463.0896 ]\n",
            " [463.06638]\n",
            " [462.99976]\n",
            " [462.82486]\n",
            " [462.69485]\n",
            " [463.11475]\n",
            " [462.71436]\n",
            " [463.0526 ]\n",
            " [463.4134 ]\n",
            " [463.32892]\n",
            " [463.2567 ]\n",
            " [462.87183]\n",
            " [463.0176 ]\n",
            " [462.66388]\n",
            " [462.73004]\n",
            " [462.86636]\n",
            " [463.14484]\n",
            " [463.26578]\n",
            " [463.1597 ]\n",
            " [462.8974 ]\n",
            " [462.71262]\n",
            " [462.90585]\n",
            " [462.81363]\n",
            " [462.7423 ]\n",
            " [462.4994 ]\n",
            " [462.68036]\n",
            " [462.7716 ]\n",
            " [462.49362]\n",
            " [462.5482 ]\n",
            " [462.38474]\n",
            " [462.71655]\n",
            " [462.4289 ]\n",
            " [462.48984]\n",
            " [462.47913]\n",
            " [462.26117]\n",
            " [462.25024]\n",
            " [462.23978]]\n",
            "tf.Tensor(\n",
            "[196. 195. 194. 193. 192. 191. 190. 189. 188. 187. 186. 185. 184. 183.\n",
            " 182. 181. 180. 179. 178. 177. 176. 175. 174. 173. 172. 171. 170. 169.\n",
            " 168. 167. 166. 165. 164. 163. 162. 161. 160. 159. 158. 157. 156. 155.\n",
            " 154. 153. 152. 151. 150. 149. 148. 147. 146. 145. 144. 143. 142. 141.\n",
            " 140. 139. 138. 137. 136. 135. 134. 133.], shape=(64,), dtype=float32)\n",
            "[[462.005  ]\n",
            " [462.3268 ]\n",
            " [461.967  ]\n",
            " [462.4233 ]\n",
            " [461.8906 ]\n",
            " [462.12576]\n",
            " [461.7075 ]\n",
            " [461.8931 ]\n",
            " [461.79596]\n",
            " [461.82306]\n",
            " [461.69083]\n",
            " [461.7056 ]\n",
            " [461.63797]\n",
            " [461.95496]\n",
            " [461.81204]\n",
            " [461.71094]\n",
            " [461.70596]\n",
            " [461.52023]\n",
            " [461.80304]\n",
            " [461.53778]\n",
            " [461.57898]\n",
            " [461.32736]\n",
            " [461.5149 ]\n",
            " [461.60312]\n",
            " [461.27032]\n",
            " [461.36005]\n",
            " [461.08044]\n",
            " [460.82962]\n",
            " [461.34796]\n",
            " [461.4426 ]\n",
            " [461.07794]\n",
            " [461.06244]\n",
            " [461.34915]\n",
            " [461.02725]\n",
            " [461.0046 ]\n",
            " [461.08478]\n",
            " [461.10193]\n",
            " [461.02255]\n",
            " [460.8557 ]\n",
            " [461.05167]\n",
            " [460.95343]\n",
            " [460.52975]\n",
            " [460.83594]\n",
            " [460.9264 ]\n",
            " [460.19937]\n",
            " [460.6341 ]\n",
            " [460.31155]\n",
            " [460.55502]\n",
            " [460.49792]\n",
            " [460.4108 ]\n",
            " [460.60562]\n",
            " [460.35   ]\n",
            " [460.30707]\n",
            " [460.85526]\n",
            " [460.76938]\n",
            " [460.65472]\n",
            " [460.80026]\n",
            " [460.6979 ]\n",
            " [460.4819 ]\n",
            " [460.53293]\n",
            " [460.63818]\n",
            " [460.25635]\n",
            " [460.6218 ]\n",
            " [459.85574]]\n",
            "tf.Tensor(\n",
            "[132. 131. 130. 129. 128. 127. 126. 125. 124. 123. 122. 121. 120. 119.\n",
            " 118. 117. 116. 115. 114. 113. 112. 111. 110. 109. 108. 107. 106. 105.\n",
            " 104. 103. 102. 101. 100.  99.  98.  97.  96.  95.  94.  93.  92.  91.\n",
            "  90.  89.  88.  87.  86.  85.  84.  83.  82.  81.  80.  79.  78.  77.\n",
            "  76.  75.  74.  73.  72.  71.  70.  69.], shape=(64,), dtype=float32)\n",
            "[[460.0498 ]\n",
            " [460.12006]\n",
            " [460.1848 ]\n",
            " [460.20374]\n",
            " [460.06476]\n",
            " [460.16458]\n",
            " [460.20563]\n",
            " [460.15234]\n",
            " [459.8969 ]\n",
            " [459.79364]\n",
            " [460.2603 ]\n",
            " [459.83548]\n",
            " [460.097  ]\n",
            " [460.01346]\n",
            " [460.2943 ]\n",
            " [459.85022]\n",
            " [460.10693]\n",
            " [460.12415]\n",
            " [459.98367]\n",
            " [459.7838 ]\n",
            " [460.11737]\n",
            " [460.27618]\n",
            " [460.27478]\n",
            " [460.0174 ]\n",
            " [459.96732]\n",
            " [460.17593]\n",
            " [460.08365]\n",
            " [460.33075]\n",
            " [460.73212]\n",
            " [460.46155]\n",
            " [460.65298]\n",
            " [460.74774]\n",
            " [460.92776]\n",
            " [460.4826 ]\n",
            " [460.26138]\n",
            " [460.46204]\n",
            " [460.17133]\n",
            " [460.18158]\n",
            " [460.3311 ]\n",
            " [460.20724]\n",
            " [460.24753]\n",
            " [460.14597]\n",
            " [460.3242 ]\n",
            " [460.11237]\n",
            " [460.47958]\n",
            " [460.23248]\n",
            " [460.27536]\n",
            " [459.99588]\n",
            " [459.7054 ]\n",
            " [459.73532]\n",
            " [459.61755]\n",
            " [459.57104]\n",
            " [459.86273]\n",
            " [459.5731 ]\n",
            " [459.90732]\n",
            " [459.76062]\n",
            " [459.84787]\n",
            " [459.709  ]\n",
            " [459.61694]\n",
            " [459.88522]\n",
            " [459.72232]\n",
            " [459.74207]\n",
            " [459.6967 ]\n",
            " [459.88202]]\n",
            "tf.Tensor(\n",
            "[68. 67. 66. 65. 64. 63. 62. 61. 60. 59. 58. 57. 56. 55. 54. 53. 52. 51.\n",
            " 50. 49. 48. 47. 46. 45. 44. 43. 42. 41. 40. 39. 38. 37. 36. 35. 34. 33.\n",
            " 32. 31. 30. 29. 28. 27. 26. 25. 24. 23. 22. 21. 20. 19. 18. 17. 16. 15.\n",
            " 14. 13. 12. 11. 10.  9.  8.  7.  6.  5.], shape=(64,), dtype=float32)\n",
            "[[459.73096]\n",
            " [459.6692 ]\n",
            " [459.73447]\n",
            " [459.39017]\n",
            " [459.31577]\n",
            " [460.35748]\n",
            " [460.49603]\n",
            " [460.11636]\n",
            " [460.3291 ]\n",
            " [460.0039 ]\n",
            " [459.9758 ]\n",
            " [459.79416]\n",
            " [459.578  ]\n",
            " [459.75162]\n",
            " [459.56012]\n",
            " [459.73297]\n",
            " [459.47433]\n",
            " [459.44748]\n",
            " [459.54834]\n",
            " [459.47916]\n",
            " [459.46567]\n",
            " [459.40128]\n",
            " [459.35645]\n",
            " [458.88095]\n",
            " [459.31882]\n",
            " [459.2838 ]\n",
            " [459.68744]\n",
            " [459.5839 ]\n",
            " [459.45126]\n",
            " [459.63104]\n",
            " [459.82712]\n",
            " [460.16904]\n",
            " [459.83817]\n",
            " [460.22397]\n",
            " [459.7955 ]\n",
            " [460.05292]\n",
            " [459.7759 ]\n",
            " [459.9423 ]\n",
            " [459.6579 ]\n",
            " [460.01303]\n",
            " [460.12106]\n",
            " [459.9391 ]\n",
            " [460.16046]\n",
            " [460.15195]\n",
            " [460.48273]\n",
            " [460.2565 ]\n",
            " [460.18948]\n",
            " [460.16876]\n",
            " [460.20798]\n",
            " [460.05072]\n",
            " [460.17532]\n",
            " [460.39423]\n",
            " [460.6563 ]\n",
            " [460.2317 ]\n",
            " [460.42062]\n",
            " [460.32364]\n",
            " [460.61325]\n",
            " [460.61722]\n",
            " [460.70258]\n",
            " [460.8405 ]\n",
            " [460.49677]\n",
            " [460.86652]\n",
            " [460.92404]\n",
            " [461.21033]]\n",
            "tf.Tensor(\n",
            "[  4.   3.   2.   1.   0. 753. 752. 751. 750. 749. 748. 747. 746. 745.\n",
            " 744. 743. 742. 741. 740. 739. 738. 737. 736. 735. 734. 733. 732. 731.\n",
            " 730. 729. 728. 727. 726. 725. 724. 723. 722. 721. 720. 719. 718. 717.\n",
            " 716. 715. 714. 713. 712. 711. 710. 709. 708. 707. 706. 705. 704. 703.\n",
            " 702. 701. 700. 699. 698. 697. 696. 695.], shape=(64,), dtype=float32)\n",
            "[[461.332  ]\n",
            " [461.21405]\n",
            " [461.43723]\n",
            " [461.54224]\n",
            " [461.556  ]\n",
            " [461.48892]\n",
            " [461.52786]\n",
            " [461.56262]\n",
            " [461.45724]\n",
            " [462.15463]\n",
            " [461.79938]\n",
            " [461.76196]\n",
            " [461.86   ]\n",
            " [462.099  ]\n",
            " [462.18143]\n",
            " [461.9102 ]\n",
            " [462.0814 ]\n",
            " [462.0777 ]\n",
            " [462.06714]\n",
            " [461.93015]\n",
            " [462.0927 ]\n",
            " [461.83102]\n",
            " [462.34024]\n",
            " [462.26303]\n",
            " [462.12292]\n",
            " [462.2278 ]\n",
            " [462.20825]\n",
            " [462.56848]\n",
            " [462.26752]\n",
            " [462.26022]\n",
            " [462.12366]\n",
            " [462.02686]\n",
            " [462.12546]\n",
            " [462.30588]\n",
            " [461.99158]\n",
            " [462.01065]\n",
            " [461.7185 ]\n",
            " [461.6129 ]\n",
            " [462.00223]\n",
            " [462.04398]\n",
            " [461.89874]\n",
            " [462.22766]\n",
            " [461.95508]\n",
            " [461.7919 ]\n",
            " [462.1443 ]\n",
            " [462.1219 ]\n",
            " [462.32346]\n",
            " [462.44086]\n",
            " [462.41293]\n",
            " [462.43134]\n",
            " [462.49255]\n",
            " [462.53876]\n",
            " [462.5647 ]\n",
            " [462.48492]\n",
            " [462.23474]\n",
            " [462.04388]\n",
            " [462.45602]\n",
            " [462.10217]\n",
            " [462.11993]\n",
            " [462.19983]\n",
            " [462.00238]\n",
            " [462.10666]\n",
            " [462.5739 ]\n",
            " [462.49976]]\n",
            "tf.Tensor(\n",
            "[694. 693. 692. 691. 690. 689. 688. 687. 686. 685. 684. 683. 682. 681.\n",
            " 680. 679. 678. 677. 676. 675. 674. 673. 672. 671. 670. 669. 668. 667.\n",
            " 666. 665. 664. 663. 662. 661. 660. 659. 658. 657. 656. 655. 654. 653.\n",
            " 652. 651. 650. 649. 648. 647. 646. 645. 644. 643. 642. 641. 640. 639.\n",
            " 638. 637. 636. 635. 634. 633. 632. 631.], shape=(64,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVHTbgnAi9HU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr = np.array()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}